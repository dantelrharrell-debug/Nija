#!/usr/bin/env python3
"""
Test Kill-Switch Reachability and Alerting System

Verifies that kill-switch can be activated in <30 seconds from all interfaces
and that the new alerting system works correctly.

Author: NIJA Trading Systems
Date: February 4, 2026
"""

import time
import sys
import json
from datetime import datetime

# Test imports
try:
    from bot.kill_switch import get_kill_switch
    from bot.monitoring_system import MonitoringSystem, AlertType, AlertLevel
    print("‚úÖ Imports successful")
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    sys.exit(1)


def test_kill_switch_activation():
    """Test kill-switch activation speed"""
    print("\n" + "=" * 70)
    print("TEST 1: Kill-Switch Activation Speed (<30 seconds requirement)")
    print("=" * 70)
    
    kill_switch = get_kill_switch()
    
    # Ensure inactive to start
    if kill_switch.is_active():
        kill_switch.deactivate("Test setup")
        time.sleep(0.1)
    
    print("Starting activation test...")
    start_time = time.time()
    
    # Test activation
    kill_switch.activate("Test activation", "TEST")
    
    activation_time = time.time() - start_time
    
    # Verify activation
    assert kill_switch.is_active(), "Kill switch not active after activation"
    
    print(f"‚úÖ Kill switch activated in {activation_time:.3f} seconds")
    
    if activation_time < 1.0:
        print("   ‚ö° EXCELLENT: Activation under 1 second")
    elif activation_time < 5.0:
        print("   ‚úÖ GOOD: Activation under 5 seconds")
    elif activation_time < 30.0:
        print("   ‚ö†Ô∏è  ACCEPTABLE: Activation under 30 seconds")
    else:
        print("   ‚ùå FAILED: Activation took too long")
        return False
    
    # Cleanup
    kill_switch.deactivate("Test cleanup")
    
    return True


def test_kill_switch_cli():
    """Test CLI interface speed"""
    print("\n" + "=" * 70)
    print("TEST 2: CLI Interface Speed")
    print("=" * 70)
    
    import subprocess
    
    start_time = time.time()
    
    result = subprocess.run(
        ['python', 'emergency_kill_switch.py', 'status'],
        capture_output=True,
        text=True,
        timeout=30
    )
    
    cli_time = time.time() - start_time
    
    assert result.returncode == 0, "CLI command failed"
    assert "KILL SWITCH STATUS" in result.stdout, "CLI output missing status"
    
    print(f"‚úÖ CLI status command completed in {cli_time:.3f} seconds")
    
    if cli_time < 2.0:
        print("   ‚ö° EXCELLENT: CLI response under 2 seconds")
    elif cli_time < 5.0:
        print("   ‚úÖ GOOD: CLI response under 5 seconds")
    elif cli_time < 30.0:
        print("   ‚ö†Ô∏è  ACCEPTABLE: CLI response under 30 seconds")
    else:
        print("   ‚ùå FAILED: CLI too slow")
        return False
    
    return True


def test_kill_switch_api():
    """Test API endpoint speed"""
    print("\n" + "=" * 70)
    print("TEST 3: API Endpoint Speed")
    print("=" * 70)
    
    print("‚ö†Ô∏è  API server not running - skipping endpoint test")
    print("   To test API endpoints:")
    print("   1. Start API server: python api_server.py")
    print("   2. curl http://localhost:5000/api/emergency/kill-switch/status")
    print("   3. Verify response time <5 seconds")
    
    return True


def test_order_stuck_alert():
    """Test order stuck alert"""
    print("\n" + "=" * 70)
    print("TEST 4: Order Stuck Alert")
    print("=" * 70)
    
    monitoring = MonitoringSystem(data_dir="/tmp/test_nija_monitoring")
    
    # Track a pending order
    monitoring.track_pending_order("test_order_123")
    print("‚úÖ Order tracked")
    
    # Simulate time passing (adjust threshold for test)
    original_threshold = monitoring.max_order_age_seconds
    monitoring.max_order_age_seconds = 1  # 1 second for test
    
    time.sleep(1.5)  # Wait to trigger alert
    
    stuck_orders = monitoring.check_stuck_orders()
    
    # Restore threshold
    monitoring.max_order_age_seconds = original_threshold
    
    assert len(stuck_orders) > 0, "Order should be flagged as stuck"
    assert "test_order_123" in stuck_orders, "Test order not in stuck list"
    
    # Check alert was created
    order_stuck_alerts = [a for a in monitoring.alerts if a.alert_type == AlertType.ORDER_STUCK.value]
    assert len(order_stuck_alerts) > 0, "No ORDER_STUCK alert created"
    
    print(f"‚úÖ Order stuck alert triggered: {order_stuck_alerts[-1].message}")
    
    # Cleanup
    monitoring.complete_order("test_order_123")
    
    return True


def test_adoption_guardrail_alert():
    """Test adoption guardrail alert"""
    print("\n" + "=" * 70)
    print("TEST 5: Adoption Guardrail Alert")
    print("=" * 70)
    
    monitoring = MonitoringSystem(data_dir="/tmp/test_nija_monitoring")
    
    # Trigger guardrail with high adoption rate
    monitoring.check_adoption_guardrail(
        active_users=85,
        total_users=100,
        auto_trigger_kill_switch=False  # Don't auto-trigger in test
    )
    
    # Check alert was created
    adoption_alerts = [a for a in monitoring.alerts if a.alert_type == AlertType.ADOPTION_GUARDRAIL.value]
    assert len(adoption_alerts) > 0, "No ADOPTION_GUARDRAIL alert created"
    
    alert = adoption_alerts[-1]
    assert alert.level == AlertLevel.EMERGENCY.value, "Alert should be EMERGENCY level"
    
    print(f"‚úÖ Adoption guardrail alert triggered: {alert.message}")
    print(f"   Alert level: {alert.level}")
    print(f"   Data: {alert.data}")
    
    return True


def test_platform_exposure_alert():
    """Test platform exposure alert"""
    print("\n" + "=" * 70)
    print("TEST 6: Platform Exposure Alert")
    print("=" * 70)
    
    monitoring = MonitoringSystem(data_dir="/tmp/test_nija_monitoring")
    
    # Trigger exposure alert with high concentration
    monitoring.check_platform_exposure(
        platform_balances={
            'Coinbase': 4000.0,
            'Kraken': 500.0,
            'Binance': 500.0
        },
        total_balance=5000.0,
        auto_trigger_kill_switch=False  # Don't auto-trigger in test
    )
    
    # Check alert was created
    exposure_alerts = [a for a in monitoring.alerts if a.alert_type == AlertType.PLATFORM_EXPOSURE.value]
    assert len(exposure_alerts) > 0, "No PLATFORM_EXPOSURE alert created"
    
    alert = exposure_alerts[-1]
    print(f"‚úÖ Platform exposure alert triggered: {alert.message}")
    print(f"   Alert level: {alert.level}")
    print(f"   Data: {alert.data}")
    
    return True


def test_kill_switch_status_api():
    """Test kill-switch status can be retrieved"""
    print("\n" + "=" * 70)
    print("TEST 7: Kill-Switch Status Retrieval")
    print("=" * 70)
    
    kill_switch = get_kill_switch()
    status = kill_switch.get_status()
    
    required_fields = ['is_active', 'kill_file_exists', 'kill_file_path', 'recent_history']
    
    for field in required_fields:
        assert field in status, f"Missing field: {field}"
    
    print("‚úÖ Status fields present:")
    for field, value in status.items():
        print(f"   {field}: {value}")
    
    return True


def main():
    """Run all tests"""
    print("\n" + "=" * 70)
    print("NIJA OPERATIONAL SAFETY TEST SUITE")
    print("=" * 70)
    print(f"Test started: {datetime.utcnow().isoformat()}")
    print()
    
    tests = [
        ("Kill-Switch Activation Speed", test_kill_switch_activation),
        ("CLI Interface Speed", test_kill_switch_cli),
        ("API Endpoint Speed", test_kill_switch_api),
        ("Order Stuck Alert", test_order_stuck_alert),
        ("Adoption Guardrail Alert", test_adoption_guardrail_alert),
        ("Platform Exposure Alert", test_platform_exposure_alert),
        ("Kill-Switch Status Retrieval", test_kill_switch_status_api),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = test_func()
            results.append((test_name, success, None))
        except Exception as e:
            print(f"\n‚ùå TEST FAILED: {test_name}")
            print(f"   Error: {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False, str(e)))
    
    # Print summary
    print("\n" + "=" * 70)
    print("TEST SUMMARY")
    print("=" * 70)
    
    passed = sum(1 for _, success, _ in results if success)
    total = len(results)
    
    for test_name, success, error in results:
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status}: {test_name}")
        if error:
            print(f"       Error: {error}")
    
    print("=" * 70)
    print(f"Results: {passed}/{total} tests passed ({passed/total*100:.1f}%)")
    print("=" * 70)
    
    if passed == total:
        print("\nüéâ ALL TESTS PASSED - Operational safety features working correctly!")
        return 0
    else:
        print(f"\n‚ö†Ô∏è  {total - passed} test(s) failed - Review output above")
        return 1


if __name__ == '__main__':
    sys.exit(main())
